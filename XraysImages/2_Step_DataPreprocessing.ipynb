{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Step - Preprocessing the merged Datasets\n",
    "\n",
    "Original Source: https://github.com/lindawangg/COVID-Net/blob/master/preprocessing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conda info --envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the data\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Set parameters here \n",
    "INPUT_SIZE = (224, 224)\n",
    "mapping = {'normal': 0, 'bacteria': 1, 'viral': 2, 'COVID-19': 3}\n",
    "\n",
    "#Gleiches Mapping \n",
    "train_filepath = 'train_split.txt'\n",
    "test_filepath = 'test_split.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the train and test files\n",
    "file = open(train_filepath, 'r') \n",
    "trainfiles = file.readlines() \n",
    "file = open(test_filepath, 'r')\n",
    "testfiles = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total samples for train: ', len(trainfiles))\n",
    "print('Total samples for test: ', len(testfiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in images\n",
    "# resize to input size and normalize to 0 - 1\n",
    "x_train = []\n",
    "x_test = []\n",
    "y_train = []\n",
    "y_test = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Only for Interpretation\n",
    "test_i = testfiles[i].split()\n",
    "print(test_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(testfiles)):\n",
    "    test_i = testfiles[i].split()\n",
    "    imgpath = test_i[1]\n",
    "    img = cv2.imread(os.path.join('COVIDx_data', 'test', imgpath))\n",
    "    img = cv2.resize(img, INPUT_SIZE) # resize\n",
    "    img = img.astype('float32') / 255.0\n",
    "    x_test.append(img)\n",
    "    y_test.append(mapping[test_i[2]])\n",
    "\n",
    "print('Shape of test images: ', x_test[0].shape)\n",
    "\n",
    "for i in range(len(trainfiles)):\n",
    "    train_i = trainfiles[i].split()\n",
    "    imgpath = train_i[1]\n",
    "    img = cv2.imread(os.path.join('COVIDx_data', 'train', imgpath))\n",
    "    img = cv2.resize(img, INPUT_SIZE) # resize\n",
    "    img = img.astype('float32') / 255.0\n",
    "    x_train.append(img)\n",
    "    y_train.append(mapping[train_i[2]])\n",
    "\n",
    "print('Shape of train images: ', x_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to npy to load in for training\n",
    "np.save('COVIDx_npy_Files/x_train.npy', x_train)\n",
    "np.save('COVIDx_npy_Files/y_train.npy', y_train)\n",
    "np.save('COVIDx_npy_Files/x_test.npy', x_test)\n",
    "np.save('COVIDx_npy_Files/y_test.npy', y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
